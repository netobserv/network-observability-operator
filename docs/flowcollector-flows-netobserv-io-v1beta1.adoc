// Automatically generated by 'openshift-apidocs-gen'. Do not edit.
:_content-type: REFERENCE
[id="network-observability-flowcollector-api-specifications_{context}"]
= FlowCollector API specifications



Description::
+
--
FlowCollector is the schema for the network flows collection API, which pilots and configures the underlying deployments.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `apiVersion`
| `string`
| APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources

| `kind`
| `string`
| Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds

| `metadata`
| `object`
| Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata

| `spec`
| `object`
| FlowCollectorSpec defines the desired state of FlowCollector.  +
 +
 *: the mention of _"unsupported"_, or _"deprecated"_ for a feature throughout this document means that this feature is not officially supported by Red Hat. It may have been, for instance, contributed by the community and accepted without a formal agreement for maintenance. The product maintainers may provide some support for these features as a best effort only.

|===
== .metadata
Description::
+
--
Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
--

Type::
  `object`




== .spec
Description::
+
--
FlowCollectorSpec defines the desired state of FlowCollector.  +
 +
 *: the mention of _"unsupported"_, or _"deprecated"_ for a feature throughout this document means that this feature is not officially supported by Red Hat. It may have been, for instance, contributed by the community and accepted without a formal agreement for maintenance. The product maintainers may provide some support for these features as a best effort only.
--

Type::
  `object`

Required::
  - `agent`
  - `deploymentModel`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `agent`
| `object`
| agent for flows extraction.

| `consolePlugin`
| `object`
| consolePlugin defines the settings related to the {product-title} Console plugin, when available.

| `deploymentModel`
| `string`
| deploymentModel defines the desired type of deployment for flow processing. Possible values are "DIRECT" (default) to make the flow processor listening directly from the agents, or "KAFKA" to make flows sent to a Kafka pipeline before consumption by the processor. Kafka can provide better scalability, resiliency and high availability (for more details, see https://www.redhat.com/en/topics/integration/what-is-apache-kafka).

| `exporters`
| `array`
| exporters define additional optional exporters for custom consumption or storage.

| `exporters[]`
| `object`
| FlowCollectorExporter defines an additional exporter to send enriched flows to.

| `kafka`
| `object`
| kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the "spec.deploymentModel" is "KAFKA".

| `loki`
| `object`
| loki, the flow store, client settings.

| `namespace`
| `string`
| namespace where NetObserv pods are deployed. If empty, the namespace of the operator is going to be used.

| `processor`
| `object`
| processor defines the settings of the component that receives the flows from the agent, enriches them, and forwards them to the Loki persistence layer.

|===
== .spec.agent
Description::
+
--
agent for flows extraction.
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `ebpf`
| `object`
| ebpf describes the settings related to the eBPF-based flow reporter when the "agent.type" property is set to "EBPF".

| `ipfix`
| `object`
| ipfix - _deprecated (*)_ - describes the settings related to the IPFIX-based flow reporter when the "agent.type" property is set to "IPFIX".

| `type`
| `string`
| type selects the flows tracing agent. Possible values are "EBPF" (default) to use NetObserv eBPF agent, "IPFIX" - _deprecated (*)_ - to use the legacy IPFIX collector. "EBPF" is recommended in most cases as it offers better performances and should work regardless of the CNI installed on the cluster. "IPFIX" works with OVN-Kubernetes CNI (other CNIs could work if they support exporting IPFIX, but they would require manual configuration).

|===
== .spec.agent.ebpf
Description::
+
--
ebpf describes the settings related to the eBPF-based flow reporter when the "agent.type" property is set to "EBPF".
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `cacheActiveTimeout`
| `string`
| cacheActiveTimeout is the max period during which the reporter will aggregate flows before sending. Increasing `cacheMaxFlows` and `cacheActiveTimeout` can decrease the network traffic overhead and the CPU load, however you can expect higher memory consumption and an increased latency in the flow collection.

| `cacheMaxFlows`
| `integer`
| cacheMaxFlows is the max number of flows in an aggregate; when reached, the reporter sends the flows. Increasing `cacheMaxFlows` and `cacheActiveTimeout` can decrease the network traffic overhead and the CPU load, however you can expect higher memory consumption and an increased latency in the flow collection.

| `debug`
| `object`
| Debug allows setting some aspects of the internal configuration of the eBPF agent. This section is aimed exclusively for debugging and fine-grained performance optimizations (for example GOGC, GOMAXPROCS env vars). Users setting its values do it at their own risk.

| `excludeInterfaces`
| `array (string)`
| excludeInterfaces contains the interface names that will be excluded from flow tracing. If an entry is enclosed by slashes (such as `/br-/`), it will match as regular expression, otherwise it will be matched as a case-sensitive string.

| `imagePullPolicy`
| `string`
| imagePullPolicy is the Kubernetes pull policy for the image defined above

| `interfaces`
| `array (string)`
| interfaces contains the interface names from where flows will be collected. If empty, the agent will fetch all the interfaces in the system, excepting the ones listed in ExcludeInterfaces. If an entry is enclosed by slashes (such as `/br-/`), it will match as regular expression, otherwise it will be matched as a case-sensitive string.

| `kafkaBatchSize`
| `integer`
| kafkaBatchSize limits the maximum size of a request in bytes before being sent to a partition. Ignored when not using Kafka. Default: 10MB.

| `logLevel`
| `string`
| logLevel defines the log level for the NetObserv eBPF Agent

| `privileged`
| `boolean`
| privileged mode for the eBPF Agent container. In general this setting can be ignored or set to false: in that case, the operator will set granular capabilities (BPF, PERFMON, NET_ADMIN, SYS_RESOURCE) to the container, to enable its correct operation. If for some reason these capabilities cannot be set (for example old kernel version not knowing CAP_BPF) then you can turn on this mode for more global privileges.

| `resources`
| `object`
| resources are the compute resources required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `sampling`
| `integer`
| sampling rate of the flow reporter. 100 means one flow on 100 is sent. 0 or 1 means all flows are sampled.

|===
== .spec.agent.ebpf.debug
Description::
+
--
Debug allows setting some aspects of the internal configuration of the eBPF agent. This section is aimed exclusively for debugging and fine-grained performance optimizations (for example GOGC, GOMAXPROCS env vars). Users setting its values do it at their own risk.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `env`
| `object (string)`
| env allows passing custom environment variables to the NetObserv Agent. Useful for passing some very concrete performance-tuning options (such as GOGC, GOMAXPROCS) that shouldn't be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug and support scenarios.

|===
== .spec.agent.ebpf.resources
Description::
+
--
resources are the compute resources required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
== .spec.agent.ipfix
Description::
+
--
ipfix - _deprecated (*)_ - describes the settings related to the IPFIX-based flow reporter when the "agent.type" property is set to "IPFIX".
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `cacheActiveTimeout`
| `string`
| cacheActiveTimeout is the max period during which the reporter will aggregate flows before sending

| `cacheMaxFlows`
| `integer`
| cacheMaxFlows is the max number of flows in an aggregate; when reached, the reporter sends the flows

| `clusterNetworkOperator`
| `object`
| clusterNetworkOperator defines the settings related to the {product-title} Cluster Network Operator, when available.

| `forceSampleAll`
| `boolean`
| forceSampleAll allows disabling sampling in the IPFIX-based flow reporter. It is not recommended to sample all the traffic with IPFIX, as it might generate cluster instability. If you REALLY want to do that, set this flag to true. Use at your own risk. When it is set to true, the value of "sampling" is ignored.

| `ovnKubernetes`
| `object`
| ovnKubernetes defines the settings of the OVN-Kubernetes CNI, when available. This configuration is used when using OVN's IPFIX exports, without {product-title}. When using OpenShift, refer to the `clusterNetworkOperator` property instead.

| `sampling`
| `integer`
| sampling is the sampling rate on the reporter. 100 means one flow on 100 is sent. To ensure cluster stability, it is not possible to set a value below 2. If you really want to sample every packet, which might impact the cluster stability, refer to "forceSampleAll". Alternatively, you can use the eBPF Agent instead of IPFIX.

|===
== .spec.agent.ipfix.clusterNetworkOperator
Description::
+
--
clusterNetworkOperator defines the settings related to the {product-title} Cluster Network Operator, when available.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `namespace`
| `string`
| namespace  where the config map is going to be deployed.

|===
== .spec.agent.ipfix.ovnKubernetes
Description::
+
--
ovnKubernetes defines the settings of the OVN-Kubernetes CNI, when available. This configuration is used when using OVN's IPFIX exports, without {product-title}. When using OpenShift, refer to the `clusterNetworkOperator` property instead.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `containerName`
| `string`
| containerName defines the name of the container to configure for IPFIX.

| `daemonSetName`
| `string`
| daemonSetName defines the name of the DaemonSet controlling the OVN-Kubernetes pods.

| `namespace`
| `string`
| namespace where OVN-Kubernetes pods are deployed.

|===
== .spec.consolePlugin
Description::
+
--
consolePlugin defines the settings related to the {product-title} Console plugin, when available.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `autoscaler`
| `object`
| autoscaler spec of a horizontal pod autoscaler to set up for the plugin Deployment. Please refer to HorizontalPodAutoscaler documentation (autoscaling/v2).

| `imagePullPolicy`
| `string`
| imagePullPolicy is the Kubernetes pull policy for the image defined above

| `logLevel`
| `string`
| logLevel for the console plugin backend

| `port`
| `integer`
| port is the plugin service port. Do not use 9002, which is reserved for metrics.

| `portNaming`
| `object`
| portNaming defines the configuration of the port-to-service name translation

| `quickFilters`
| `array`
| quickFilters configures quick filter presets for the Console plugin

| `quickFilters[]`
| `object`
| QuickFilter defines preset configuration for Console's quick filters

| `register`
| `boolean`
| register allows, when set to true, to automatically register the provided console plugin with the {product-title} Console operator. When set to false, you can still register it manually by editing console.operator.openshift.io/cluster. E.g: oc patch console.operator.openshift.io cluster --type='json' -p '[{"op": "add", "path": "/spec/plugins/-", "value": "netobserv-plugin"}]'

| `replicas`
| `integer`
| replicas defines the number of replicas (pods) to start.

| `resources`
| `object`
| resources, in terms of compute resources, required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
== .spec.consolePlugin.autoscaler
Description::
+
--
autoscaler spec of a horizontal pod autoscaler to set up for the plugin Deployment. Please refer to HorizontalPodAutoscaler documentation (autoscaling/v2).
--

Type::
  `object`




== .spec.consolePlugin.portNaming
Description::
+
--
portNaming defines the configuration of the port-to-service name translation
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `enable`
| `boolean`
| enable the console plugin port-to-service name translation

| `portNames`
| `object (string)`
| portNames defines additional port names to use in the console. Example: portNames: {"3100": "loki"}

|===
== .spec.consolePlugin.quickFilters
Description::
+
--
quickFilters configures quick filter presets for the Console plugin
--

Type::
  `array`




== .spec.consolePlugin.quickFilters[]
Description::
+
--
QuickFilter defines preset configuration for Console's quick filters
--

Type::
  `object`

Required::
  - `filter`
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `default`
| `boolean`
| default defines whether this filter should be active by default or not

| `filter`
| `object (string)`
| filter is a set of keys and values to be set when this filter is selected. Each key can relate to a list of values using a coma-separated string. Example: filter: {"src_namespace": "namespace1,namespace2"}

| `name`
| `string`
| name of the filter, that will be displayed in Console

|===
== .spec.consolePlugin.resources
Description::
+
--
resources, in terms of compute resources, required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
== .spec.exporters
Description::
+
--
exporters define additional optional exporters for custom consumption or storage.
--

Type::
  `array`




== .spec.exporters[]
Description::
+
--
FlowCollectorExporter defines an additional exporter to send enriched flows to.
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `ipfix`
| `object`
| IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to. _Unsupported (*)_.

| `kafka`
| `object`
| kafka configuration, such as the address and topic, to send enriched flows to.

| `type`
| `string`
| type selects the type of exporters. The available options are "KAFKA" and "IPFIX". "IPFIX" is _unsupported (*)_.

|===
== .spec.exporters[].ipfix
Description::
+
--
IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to. _Unsupported (*)_.
--

Type::
  `object`

Required::
  - `targetHost`
  - `targetPort`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `targetHost`
| `string`
| address of the ipfix external receiver

| `targetPort`
| `integer`
| port for the ipfix external receiver

| `transport`
| `string`
| Transport protocol (tcp/udp) to be used for the IPFIX connection, defaults to tcp

|===
== .spec.exporters[].kafka
Description::
+
--
kafka configuration, such as the address and topic, to send enriched flows to.
--

Type::
  `object`

Required::
  - `address`
  - `topic`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `address`
| `string`
| address of the Kafka server

| `tls`
| `object`
| tls client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093. Note that, when eBPF agents are used, Kafka certificate needs to be copied in the agent namespace (by default it's netobserv-privileged).

| `topic`
| `string`
| kafka topic to use. It must exist, NetObserv will not create it.

|===
== .spec.exporters[].kafka.tls
Description::
+
--
tls client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093. Note that, when eBPF agents are used, Kafka certificate needs to be copied in the agent namespace (by default it's netobserv-privileged).
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `caCert`
| `object`
| caCert defines the reference of the certificate for the Certificate Authority

| `enable`
| `boolean`
| enable TLS

| `insecureSkipVerify`
| `boolean`
| insecureSkipVerify allows skipping client-side verification of the server certificate If set to true, CACert field will be ignored

| `userCert`
| `object`
| userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)

|===
== .spec.exporters[].kafka.tls.caCert
Description::
+
--
caCert defines the reference of the certificate for the Certificate Authority
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.exporters[].kafka.tls.userCert
Description::
+
--
userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.kafka
Description::
+
--
kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the "spec.deploymentModel" is "KAFKA".
--

Type::
  `object`

Required::
  - `address`
  - `topic`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `address`
| `string`
| address of the Kafka server

| `tls`
| `object`
| tls client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093. Note that, when eBPF agents are used, Kafka certificate needs to be copied in the agent namespace (by default it's netobserv-privileged).

| `topic`
| `string`
| kafka topic to use. It must exist, NetObserv will not create it.

|===
== .spec.kafka.tls
Description::
+
--
tls client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093. Note that, when eBPF agents are used, Kafka certificate needs to be copied in the agent namespace (by default it's netobserv-privileged).
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `caCert`
| `object`
| caCert defines the reference of the certificate for the Certificate Authority

| `enable`
| `boolean`
| enable TLS

| `insecureSkipVerify`
| `boolean`
| insecureSkipVerify allows skipping client-side verification of the server certificate If set to true, CACert field will be ignored

| `userCert`
| `object`
| userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)

|===
== .spec.kafka.tls.caCert
Description::
+
--
caCert defines the reference of the certificate for the Certificate Authority
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.kafka.tls.userCert
Description::
+
--
userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.loki
Description::
+
--
loki, the flow store, client settings.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `authToken`
| `string`
| AuthToken describe the way to get a token to authenticate to Loki. DISABLED will not send any token with the request. HOST - _deprecated (*)_ - will use the local pod service account to authenticate to Loki. FORWARD will forward the user token for authorization. When using the Loki Operator, this should be set to `FORWARD`.

| `batchSize`
| `integer`
| batchSize is max batch size (in bytes) of logs to accumulate before sending.

| `batchWait`
| `string`
| batchWait is max time to wait before sending a batch.

| `maxBackoff`
| `string`
| maxBackoff is the maximum backoff time for client connection between retries.

| `maxRetries`
| `integer`
| maxRetries is the maximum number of retries for client connections.

| `minBackoff`
| `string`
| minBackoff is the initial backoff time for client connection between retries.

| `querierUrl`
| `string`
| querierURL specifies the address of the Loki querier service, in case it is different from the Loki ingester URL. If empty, the URL value will be used (assuming that the Loki ingester and querier are in the same server). When using the Loki Operator, do not set it, since ingestion and queries use the Loki gateway.

| `staticLabels`
| `object (string)`
| staticLabels is a map of common labels to set on each flow.

| `statusTls`
| `object`
| tls client configuration for loki status URL.

| `statusUrl`
| `string`
| statusURL specifies the address of the Loki /ready /metrics /config endpoints, in case it is different from the Loki querier URL. If empty, the QuerierURL value will be used. This is useful to show error messages and some context in the frontend. When using the Loki Operator, set it to the Loki HTTP query frontend service, for example https://loki-query-frontend-http.netobserv.svc:3100/. statusTLS configuration will be used when statusUrl is set.

| `tenantID`
| `string`
| tenantID is the Loki X-Scope-OrgID that identifies the tenant for each request. When using the Loki Operator, set it to `network`, which corresponds to a special tenant mode.

| `timeout`
| `string`
| timeout is the maximum time connection / request limit. A Timeout of zero means no timeout.

| `tls`
| `object`
| tls client configuration for loki URL.

| `url`
| `string`
| url is the address of an existing Loki service to push the flows to. When using the Loki Operator, set it to the Loki gateway service with the `network` tenant set in path, for example https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network.

|===
== .spec.loki.statusTls
Description::
+
--
tls client configuration for loki status URL.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `caCert`
| `object`
| caCert defines the reference of the certificate for the Certificate Authority

| `enable`
| `boolean`
| enable TLS

| `insecureSkipVerify`
| `boolean`
| insecureSkipVerify allows skipping client-side verification of the server certificate If set to true, CACert field will be ignored

| `userCert`
| `object`
| userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)

|===
== .spec.loki.statusTls.caCert
Description::
+
--
caCert defines the reference of the certificate for the Certificate Authority
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.loki.statusTls.userCert
Description::
+
--
userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.loki.tls
Description::
+
--
tls client configuration for loki URL.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `caCert`
| `object`
| caCert defines the reference of the certificate for the Certificate Authority

| `enable`
| `boolean`
| enable TLS

| `insecureSkipVerify`
| `boolean`
| insecureSkipVerify allows skipping client-side verification of the server certificate If set to true, CACert field will be ignored

| `userCert`
| `object`
| userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)

|===
== .spec.loki.tls.caCert
Description::
+
--
caCert defines the reference of the certificate for the Certificate Authority
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.loki.tls.userCert
Description::
+
--
userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.processor
Description::
+
--
processor defines the settings of the component that receives the flows from the agent, enriches them, and forwards them to the Loki persistence layer.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `conversationEndTimeout`
| `string`
| conversation end timeout is the duration of time to wait from the last flow log to end a conversation

| `conversationHeartbeatInterval`
| `string`
| conversation heartbeat interval is the duration of time to wait between heartbeat reports of a conversation

| `debug`
| `object`
| Debug allows setting some aspects of the internal configuration of the flow processor. This section is aimed exclusively for debugging and fine-grained performance optimizations (for example GOGC, GOMAXPROCS env vars). Users setting its values do it at their own risk.

| `dropUnusedFields`
| `boolean`
| dropUnusedFields allows, when set to true, to drop fields that are known to be unused by OVS, in order to save storage space.

| `enableKubeProbes`
| `boolean`
| enableKubeProbes is a flag to enable or disable Kubernetes liveness and readiness probes

| `healthPort`
| `integer`
| healthPort is a collector HTTP port in the Pod that exposes the health check API

| `imagePullPolicy`
| `string`
| imagePullPolicy is the Kubernetes pull policy for the image defined above

| `kafkaConsumerAutoscaler`
| `object`
| kafkaConsumerAutoscaler spec of a horizontal pod autoscaler to set up for flowlogs-pipeline-transformer, which consumes Kafka messages. This setting is ignored when Kafka is disabled. Please refer to HorizontalPodAutoscaler documentation (autoscaling/v2).

| `kafkaConsumerBatchSize`
| `integer`
| kafkaConsumerBatchSize indicates to the broker the maximum batch size, in bytes, that the consumer will accept. Ignored when not using Kafka. Default: 10MB.

| `kafkaConsumerQueueCapacity`
| `integer`
| kafkaConsumerQueueCapacity defines the capacity of the internal message queue used in the Kafka consumer client. Ignored when not using Kafka.

| `kafkaConsumerReplicas`
| `integer`
| kafkaConsumerReplicas defines the number of replicas (pods) to start for flowlogs-pipeline-transformer, which consumes Kafka messages. This setting is ignored when Kafka is disabled.

| `logLevel`
| `string`
| logLevel of the collector runtime

| `logTypes`
| `string`
| logTypes defines the desired record types to generate. Possible values are "FLOWS" (default) to export flowLogs, "CONVERSATIONS" to generate newConnection, heartbeat, endConnection events, "ENDED_CONVERSATIONS" to generate only endConnection events or "ALL" to generate both flow logs and conversations events

| `metrics`
| `object`
| Metrics define the processor configuration regarding metrics

| `port`
| `integer`
| port of the flow collector (host port) By conventions, some value are not authorized port must not be below 1024 and must not equal this values: 4789,6081,500, and 4500

| `profilePort`
| `integer`
| profilePort allows setting up a Go pprof profiler listening to this port

| `resources`
| `object`
| resources are the compute resources required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
== .spec.processor.debug
Description::
+
--
Debug allows setting some aspects of the internal configuration of the flow processor. This section is aimed exclusively for debugging and fine-grained performance optimizations (for example GOGC, GOMAXPROCS env vars). Users setting its values do it at their own risk.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `env`
| `object (string)`
| env allows passing custom environment variables to the NetObserv Agent. Useful for passing some very concrete performance-tuning options (such as GOGC, GOMAXPROCS) that shouldn't be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug and support scenarios.

|===
== .spec.processor.kafkaConsumerAutoscaler
Description::
+
--
kafkaConsumerAutoscaler spec of a horizontal pod autoscaler to set up for flowlogs-pipeline-transformer, which consumes Kafka messages. This setting is ignored when Kafka is disabled. Please refer to HorizontalPodAutoscaler documentation (autoscaling/v2).
--

Type::
  `object`




== .spec.processor.metrics
Description::
+
--
Metrics define the processor configuration regarding metrics
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `disableAlerts`
| `array (string)`
| disableAlerts is a list of alerts that should be disabled. Possible values are: `NetObservNoFlows`, which is triggered when no flows are being observed for a certain period. `NetObservLokiError`, which is triggered when flows are being dropped due to Loki errors.

| `ignoreTags`
| `array (string)`
| ignoreTags is a list of tags to specify which metrics to ignore. Each metric is associated with a list of tags. More details in https://github.com/netobserv/network-observability-operator/tree/main/controllers/flowlogspipeline/metrics_definitions . Available tags are: egress, ingress, flows, bytes, packets, namespaces, nodes, workloads

| `server`
| `object`
| metricsServer endpoint configuration for Prometheus scraper

|===
== .spec.processor.metrics.server
Description::
+
--
metricsServer endpoint configuration for Prometheus scraper
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `port`
| `integer`
| the prometheus HTTP port

| `tls`
| `object`
| TLS configuration.

|===
== .spec.processor.metrics.server.tls
Description::
+
--
TLS configuration.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `provided`
| `object`
| TLS configuration.

| `type`
| `string`
| Select the type of TLS configuration "DISABLED" (default) to not configure TLS for the endpoint, "PROVIDED" to manually provide cert file and a key file, and "AUTO" to use {product-title} auto generated certificate using annotations

|===
== .spec.processor.metrics.server.tls.provided
Description::
+
--
TLS configuration.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the config map or secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the config map or secret containing certificates

| `namespace`
| `string`
| namespace of the config map or secret containing certificates. If omitted, assumes same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret will be copied so that it can be mounted as required.

| `type`
| `string`
| type for the certificate reference: "configmap" or "secret"

|===
== .spec.processor.resources
Description::
+
--
resources are the compute resources required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===

