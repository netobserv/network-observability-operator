apiVersion: flows.netobserv.io/v1beta2
kind: FlowCollector
metadata:
  name: cluster
spec:
  namespace: netobserv
  deploymentModel: Service
  networkPolicy:
    enable: true
    additionalNamespaces: []
  agent:
    type: eBPF
    ebpf:
      # imagePullPolicy: Always
      # logLevel: debug
      sampling: 50
      cacheActiveTimeout: 15s
      cacheMaxFlows: 120000
      # Change privileged to "true" on old kernel version not knowing CAP_BPF or when using "PacketDrop" feature
      privileged: false
      # features:
      # - "PacketDrop"
      # - "DNSTracking"
      # - "FlowRTT"
      # - "NetworkEvents"
      # - "PacketTranslation"
      # - "EbpfManager"
      # - "UDNMapping"
      # - "IPSec"
      interfaces: []
      excludeInterfaces: ["lo"]
      # kafkaBatchSize: 1048576
      #flowFilter:
      #  enable: true
      #  rules:
      #  - action: Accept
      #    cidr: 0.0.0.0/0
      #  - action: Accept
      #    cidr: 10.128.0.1/24
      #    peerCIDR: 0.0.0.0/0
      #    ports: 6443
      #    protocol: TCP
      #    sampling: 10
      #  - action: Accept
      #    cidr: 10.129.0.1/24
      #    ports: 53
      #    protocol: UDP
      #    sampling: 20
      #    sourcePorts: 443
      #  - action: Accept
      #    tcpFlags: "SYN"
      #    cidr: 2.2.2.2/24
      #    protocol: TCP
      #    sourcePorts: 53
      # metrics:
      #   server:
      #     port: 9400
      # Custom optionnal resources configuration
      # resources:
      #   requests:
      #     memory: 50Mi
      #     cpu: 100m
      #   limits:
      #     memory: 800Mi
  # kafka:
  #   address: "kafka-cluster-kafka-bootstrap.netobserv"
  #   topic: network-flows
  #   tls:
  #     enable: false
  #     caCert:
  #       type: secret
  #       name: kafka-cluster-cluster-ca-cert
  #       certFile: ca.crt
  #     userCert:
  #       type: secret
  #       name: flp-kafka
  #       certFile: user.crt
  #       certKey: user.key
  processor:
    # imagePullPolicy: Always
    # logLevel: debug
    # Change logTypes to "Conversations", "EndedConversations" or "All" to enable conversation tracking
    # logTypes: Flows
    # Append a unique cluster name to each record
    # clusterName: <CLUSTER NAME>
    # addZone: true
    # subnetLabels:
    #   openShiftAutoDetect: true
    #   customLabels:
    #   - cidrs: []
    #     name: ""
    metrics:
      # server:
      #   port: 9401
      disableAlerts: []
      # includeList:
      # - "node_ingress_bytes_total"
      # - "node_ingress_packets_total"
      # - "workload_ingress_bytes_total"
      # - "workload_ingress_packets_total"
      # - "namespace_flows_total"
      # - "namespace_drop_packets_total"
      # - "node_drop_packets_total"
      # - "namespace_rtt_seconds"
      # healthRules:
      # - template: PacketDropsByKernel
      #   mode: Alert  # or "Recording" to generate recording rules instead of alerts
      #   variants:
      #   - thresholds:
      #       critical: "15"
      #       warning: "10"
      #       info: "5"
      #   - thresholds:
      #       critical: "15"
      #       warning: "10"
      #       info: "5"
      #     groupBy: Node
      #     lowVolumeThreshold: "5"
      #   - thresholds:
      #       critical: "15"
      #       warning: "10"
      #       info: "5"
      #     groupBy: Namespace
      #     lowVolumeThreshold: "5"
    slicesConfig:
      enable: false
      # collectionMode: AllowList
      # namespacesAllowList:
      # - /openshift-.*|netobserv.*/
    # FLP replicas
    consumerReplicas: 3
    # Custom optionnal resources configuration
    # resources:
    #   requests:
    #     memory: 100Mi
    #     cpu: 100m
    #   limits:
    #     memory: 800Mi
    # deduper:
    #   mode: Sample
    #   sampling: 100
    # filters:
    #   - query: |
    #       (SrcK8S_Namespace="netobserv" OR (SrcK8S_Namespace="openshift-console" AND DstK8S_Namespace="netobserv"))
    #     outputTarget: Loki
    #     sampling: 10
    # advanced:
    #   secondaryNetworks:
    #     - name: "my-vms/custom-nad"
    #       # Any of: MAC, IP, Interface
    #       index: [MAC]
  loki:
    enable: true
    # Change mode to "LokiStack" to use with the loki operator
    mode: Monolithic
    monolithic:
      # NB: trailing dot (...local.:3100) is a DNS optimization for exact name match without extra search
      url: 'http://loki.netobserv.svc.cluster.local.:3100/'
      # tenantID: netobserv
      # tls:
      #   enable: false
      #   caCert:
      #     type: configmap
      #     name: loki-gateway-ca-bundle
      #     certFile: service-ca.crt
      # Enable automatic install for dev / demo purposes
      # installDemoLoki: true
    lokiStack:
      name: loki
      # Change loki operator instance namespace
      # namespace: loki-operator
    # Console plugin read timeout
    # readTimeout: 30s
    # # Write stage configuration
    # writeTimeout: 10s
    # writeBatchWait: 1s
    # writeBatchSize: 10485760
  # prometheus:
  #   querier:
  #     enable: true
  #     mode: Auto
  #     timeout: 30s
  consolePlugin:
    enable: true
    # imagePullPolicy: Always
    # logLevel: debug
    # Scaling configuration
    # replicas: 1
    # autoscaler:
    #   status: Disabled
    #   minReplicas: 1
    #   maxReplicas: 3
    #   metrics:
    #   - type: Resource
    #     resource:
    #       name: cpu
    #       target:
    #         type: Utilization
    #         averageUtilization: 50
    # Custom optionnal port-to-service name translation
    # portNaming:
    #   enable: true
    #   portNames:
    #     "3100": loki
    # Custom optionnal filter presets
    # quickFilters:
    # - name: Applications
    #   filter:
    #     flow_layer: '"app"'
    #   default: true
    # - name: Infrastructure
    #   filter:
    #     flow_layer: '"infra"'
    # - name: Pods network
    #   filter:
    #     src_kind: '"Pod"'
    #     dst_kind: '"Pod"'
    #   default: true
    # - name: Services network
    #   filter:
    #     dst_kind: '"Service"'
    # - name: External ingress
    #   filter:
    #     src_subnet_label: '"",EXT:'
    # - name: External egress
    #   filter:
    #     dst_subnet_label: '"",EXT:'
    # Custom optionnal resources configuration
    # resources:
    #   requests:
    #     memory: 50Mi
    #     cpu: 100m
    #   limits:
    #     memory: 100Mi
  exporters: []
    # - type: Kafka
    #   kafka:
    #     address: "kafka-cluster-kafka-bootstrap.netobserv"
    #     topic: netobserv-flows-export
    # or
    # - type: IPFIX
    #   ipfix:
    #     # see https://github.com/netobserv/flowlogs-pipeline/blob/main/contrib/kubernetes/ipfix-collector-stdout.yaml
    #     targetHost: "flp-ipfix-stdout.netobserv.svc.cluster.local"
    #     targetPort: 2055
    #     transport: UDP
    #     enterpriseID: 2021
    # or
    # - type: OpenTelemetry
    #   openTelemetry:
    #     targetHost: "1.2.3.4:443"
    #     targetPort: 4317
    #     protocol: grpc
    #     logs:
    #       enable: true
    #     metrics:
    #       enable: true
    #       prefix: netobserv
    #       pushTimeInterval: 20s
    #       expiryTime: 2m
